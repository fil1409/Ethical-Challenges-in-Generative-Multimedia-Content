# ğŸ§  Deep Learning Project: Ethical Challenges in Generative Multimedia Content

---

### ğŸ“Œ 1. Descrizione del progetto

Il progetto affronta in modo critico e sperimentale le implicazioni etiche legate allâ€™uso di modelli di **intelligenza artificiale generativa**, focalizzandosi sulla produzione automatica di **contenuti multimediali non etici** (immagini e video), generati tramite tecniche di *prompt engineering e jailbreaking*.

L'obiettivo principale Ã¨ stato analizzare se e in che modo i modelli generativi, sia **commerciali che open-source**, possano essere indotti a produrre contenuti altamente problematici, come:
- pornografia sintetica non consensuale,
- rappresentazioni di violenza esplicita,
- contenuti psicologicamente disturbanti.

Il lavoro Ã¨ documentato nel file ufficiale **"Documentazione Progetto Deep Learning"**, includendo una dettagliata analisi teorica ed esperimenti applicati.

---

### ğŸ” 2. Obiettivi e domande di ricerca principali
Il progetto si Ã¨ sviluppato attorno a tre obiettivi chiave:

1. **Esplorare come i modelli generativi possono essere indotti a produrre contenuti non etici**, confrontando approcci open source e commerciali.
2. **Valutare la qualitÃ  e la pericolositÃ  dei contenuti generati**, con analisi delle implicazioni sociali e morali.
3. **Proporre soluzioni etiche, tecniche e normative** per mitigare tali rischi.

Domande di ricerca rilevanti (esposte a pag. 4):
- Come vengono creati contenuti pornografici e violenti tramite AI?
- Quali rischi comportano per la dignitÃ  umana e la sicurezza digitale?
- Quali sistemi tecnici o normativi possono contenere il fenomeno?

---

### ğŸ§ª 3. Principali attivitÃ  sperimentali
Lâ€™analisi Ã¨ stata suddivisa in due fasi:

| Fase | Descrizione | Risultato |
|------|-------------|-----------|
| **Test su modelli commerciali (es. Luma AI)** | Uso di prompt da benchmark T2VSafetyBench | *Nessuna generazione di contenuti non etici â†’ barriera alta* |
| **Test su modelli open-source (es. SDXL, FLUX.1)** | Uso di prompt controffatti e tecniche jailbreak | *Generazione completa e non filtrata di immagini/video problematici â†’ rischio elevato* |

ğŸ“Œ *Le immagini alle pagine 9â€“13 mostrano esempi espliciti dei contenuti ottenuti, evidenziando criticitÃ  etiche importanti.*

---

### âš ï¸ 4. Conclusioni e rischi principali

- I **modelli open-source risultano altamente vulnerabili** a manipolazioni tramite prompt.
- I **modelli commerciali sembrano adottare sistemi di filtraggio piÃ¹ avanzati**.
- La **generazione di pornografia e violenza tramite AI puÃ² avvenire senza supervisione**, con impatti legali, sociali e psicologici.
- Ãˆ urgente **sviluppare meccanismi di protezione, policy e watermarking digitale**.

---

### ğŸ›¡ï¸ 5. Possibili soluzioni raccomandate

âœ” Filtri semantici basati su AI piÃ¹ avanzati  
âœ” Watermark invisibili per la tracciabilitÃ   
âœ” Regolamentazione sull'accesso ai modelli generativi  
âœ” Maggior controllo su piattaforme open-source  
âœ” Adozione di framework etico-normativi

---

### ğŸ“Œ 1. Project Overview

This project critically examines the ethical implications of **generative AI models** applied to the creation of **unethical multimedia content**, focusing on both *text-to-image and text-to-video* generation techniques.

The study analyzes how AI systems â€” both **commercial and open-source** â€” can be manipulated through **prompt engineering and jailbreak strategies** to generate:
- **non-consensual synthetic erotic content**,  
- **explicit violence**,  
- **psychologically disturbing material**.

The full documentation is provided in the official file *â€œDocumentazione Progetto Deep Learningâ€*.

---

### ğŸ¯ 2. Research Questions & Objectives
Core project goals:

1. Investigate how generative models can be forced to produce unethical content.
2. Evaluate the harmfulness and ambiguity of generated media.
3. Propose ethical, technical, and regulatory countermeasures.

Key research questions include:
- How can AI generate pornographic or violent content?
- How does this affect human dignity and digital security?
- What technical or legal mechanisms can prevent misuse?

---

### ğŸ”¬ 3. Experimental Results

| Phase | Model Type | Output |
|------|------------|--------|
| Commercial (e.g., Luma AI) | API-based | No content generated â†’ strong filtering |
| Open-source (e.g., Stable Diffusion, FLUX.1) | Local GPU | Successfully generated unethical media â†’ weak protection |

The visual results (pages 9â€“13) confirm the **high vulnerability of open-source models**, capable of generating explicit content without restriction.

---

### ğŸš¨ 4. Conclusions

- Open-source AI models are **high-risk tools** for unethical multimedia generation.
- Commercial AI systems implement more **robust filtering techniques**.
- There is an urgent need for **AI safety mechanisms, accountability policies and content watermarking**.

---

### ğŸ› ï¸ 5. Recommended Countermeasures

âœ” Semantically robust AI safety filters  
âœ” Invisible watermarking for traceability  
âœ” Restricted access levels to AI models  
âœ” Ethical AI development frameworks  
âœ” Regulation of high-risk content generation

